{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Answers\n",
    "\n",
    "- **Questions**: [Here](../data/exercise_3/HW3.docx)\n",
    "- **Answer Set**: No. 03\n",
    "- **Full Name**: Mohammad Hosein Nemati\n",
    "- **Student Code**: `610300185`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595aa20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed694d",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "In this section we will done some basic steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cf505",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "Before begin, we must import these required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import re as re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk as nltk\n",
    "import nltk.corpus.reader.conll as nltkconll\n",
    "\n",
    "import sklearn.base as skbase\n",
    "import sklearn.utils as skutils\n",
    "import sklearn.pipeline as skpipeline\n",
    "import sklearn.preprocessing as skprocessing\n",
    "import sklearn.model_selection as skselection\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "\n",
    "import hmm.hmm as hmm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "sk.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32c3cd",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Now we will load `ConLL Format` corpus and store `TestSet` and `TrainSet`  \n",
    "Next, we will define some functions inorder to replace **OOV** with less frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = nltkconll.ConllCorpusReader(\"../lib\", [\"Train.txt\"], (\"words\", \"pos\"))\n",
    "test_reader = nltkconll.ConllCorpusReader(\"../lib\", [\"Test.txt\"], (\"words\", \"pos\"))\n",
    "\n",
    "words_frequency = nltk.FreqDist(train_reader.words())\n",
    "\n",
    "def sents(reader):\n",
    "    for sent in reader.sents():\n",
    "        yield [\n",
    "            word if (words_frequency.get(word) or 0) > 1 else \"OOV\"\n",
    "            for word in sent\n",
    "        ]\n",
    "\n",
    "def words(reader):\n",
    "    for word in reader.words():\n",
    "        if (words_frequency.get(word) or 0) > 1:\n",
    "            yield word\n",
    "        else:\n",
    "            yield \"OOV\"\n",
    "\n",
    "def tags(reader):\n",
    "    for sent in reader.tagged_sents():\n",
    "        for token in sent:\n",
    "            yield token[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Now, we will use the implemented `HMM` class and train it using **Sequence of Words** and **Sequence of Tags** of `TrainSet`  \n",
    "Then, we will use implemented `predict` method using `viterbi` algorithm to decode the **Sequence of Words** of `TestSet` and getting the predicted **Sequence of Tags**  \n",
    "Next, we will find the predicted accuracy of **Sequence of Tags**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_encoder = skprocessing.LabelEncoder().fit(list(words(train_reader)))\n",
    "tag_encoder = skprocessing.LabelEncoder().fit(list(tags(train_reader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.44935602823776\n"
     ]
    }
   ],
   "source": [
    "model = hmm.HMMEstimator(n_iter=0).fit(\n",
    "    np.array(word_encoder.transform(list(words(train_reader)))),\n",
    "    np.array(tag_encoder.transform(list(tags(train_reader)))),\n",
    "    np.array([len(sent) for sent in sents(train_reader)])\n",
    ")\n",
    "\n",
    "predicts = model.predict(\n",
    "    np.array(word_encoder.transform(list(words(test_reader)))),\n",
    "    np.array([len(sent) for sent in sents(test_reader)])\n",
    ")\n",
    "\n",
    "real_tags = list(tags(test_reader))\n",
    "predicted_tags = tag_encoder.inverse_transform(predicts)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(real_tags)):\n",
    "    if real_tags[i] == predicted_tags[i]:\n",
    "        count += 1\n",
    "\n",
    "print(f\"Accuracy: {(count / len(real_tags)) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9278c29f1c5526d5663cab0214876a9a1ad235f0a8fdeebad627cd7666833d94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
