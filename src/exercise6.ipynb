{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKjxJKf3vtrb"
   },
   "source": [
    "# NLP Answers\n",
    "\n",
    "- **Answer Set**: No. 06\n",
    "- **Full Name**: Mohammad Hosein Nemati\n",
    "- **Student Code**: `610300185`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NokCmrCkvtrk"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCrlSoh4vtrl"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this problem, we are going to use **ParsBERT** pre-trained model for **Token Classification (NER)** task on **Custom** dataset.  \n",
    "Then we will compare the reported metrics to previously trained models in `exercise 3`\n",
    "\n",
    "In the first step, we will import some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d1e4ab7"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import math as math\n",
    "import hazm as hazm\n",
    "import nltk as nltk\n",
    "import nltk.corpus.reader.conll as nltkconll\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skprocessing\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6595aa20"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4ed694d"
   },
   "source": [
    "## Loading\n",
    "\n",
    "First of all, we must load our dataset and then shuffle the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "paMlIDu6vtrr",
    "outputId": "f8f8ab33-b72b-494d-f482-201ada2b757d"
   },
   "outputs": [],
   "source": [
    "train_reader = nltkconll.ConllCorpusReader(\"../lib\", [\"Train.txt\"], (\"words\", \"pos\"))\n",
    "test_reader = nltkconll.ConllCorpusReader(\"../lib\", [\"Test.txt\"], (\"words\", \"pos\"))\n",
    "\n",
    "def rows(reader):\n",
    "    for sent in reader.tagged_sents():\n",
    "        words, tags = zip(*sent)\n",
    "        yield [list(words), list(tags)]\n",
    "\n",
    "train_frame = pd.DataFrame(rows(train_reader), columns=[\"words\", \"tags\"])\n",
    "train_frame = train_frame.sample(frac=1, random_state=313)\n",
    "\n",
    "test_frame = pd.DataFrame(rows(test_reader), columns=[\"words\", \"tags\"])\n",
    "test_frame = train_frame.sample(frac=1, random_state=313)\n",
    "\n",
    "train_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rI2REVIevtrv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHBfyoFSvtrw"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aG7Q131wvtrx"
   },
   "outputs": [],
   "source": [
    "def tags(reader):\n",
    "    for sent in reader.tagged_sents():\n",
    "        for token in sent:\n",
    "            yield token[1]\n",
    "            \n",
    "tag_encoder = skprocessing.LabelEncoder().fit(list(tags(train_reader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame[\"tags\"] = train_frame[\"tags\"].apply(lambda tags : tag_encoder.transform(tags))\n",
    "test_frame[\"tags\"] = test_frame[\"tags\"].apply(lambda tags : tag_encoder.transform(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "def tokenize(ds):\n",
    "    tokens = tokenizer(ds[\"words\"], truncation=True, padding=True, max_length=512, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(ds[\"tags\"]):\n",
    "        word_ids = tokens.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokens[\"labels\"] = labels\n",
    "    return tokens\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
    "\n",
    "trainset = Dataset.from_pandas(train_frame).map(tokenize, batched=True)\n",
    "testset = Dataset.from_pandas(test_frame).map(tokenize, batched=True)\n",
    "\n",
    "collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cowVS3e5vtry"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-8nVpIzvtrz"
   },
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fS1yFaQovtrz"
   },
   "outputs": [],
   "source": [
    "train_set = trainset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    batch_size=8,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "\n",
    "test_set = testset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    batch_size=8,\n",
    "    collate_fn=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cowVS3e5vtry"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZjZe48zvtr1"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "J7VFKYmOvtr1",
    "outputId": "64a5220e-3c21-4ed3-c372-0c9fcf134b6e"
   },
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\", num_labels=len(tag_encoder.classes_))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "mUdATQ7rvtr1",
    "outputId": "1f0b0221-612f-4918-f967-721da3134176"
   },
   "outputs": [],
   "source": [
    "model.fit(train_set, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO7tU1Xwvtr2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IVeWlHPvtr2"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "SchKxEX3vtr2",
    "outputId": "7e58b0e0-c21c-4d46-d9e4-ac4d64122129"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate([1,2])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mCfAcKlvtr3"
   },
   "source": [
    "As we can see, the **Pars BERT** pre-trained model returend much better accuracy after fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU3mpEmlvtr3"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9278c29f1c5526d5663cab0214876a9a1ad235f0a8fdeebad627cd7666833d94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
