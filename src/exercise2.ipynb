{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Answers\n",
    "\n",
    "- **Answer Set**: No. 02\n",
    "- **Full Name**: Mohammad Hosein Nemati\n",
    "- **Student Code**: `610300185`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595aa20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed694d",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "In this section we will done some basic steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cf505",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "Before begin, we must import these required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import re as re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.base as skbase\n",
    "import sklearn.utils as skutils\n",
    "import sklearn.pipeline as skpipeline\n",
    "import sklearn.preprocessing as skprocessing\n",
    "import sklearn.model_selection as skselection\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "\n",
    "import exercise_2.hmm as hmm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "sk.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import re as re\n",
    "\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.base as skbase\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=nb.NumbaPerformanceWarning)\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def _alpha(x, start_probs, transition_probs, observation_probs):\n",
    "    n_components = start_probs.shape[0]\n",
    "    alpha = np.zeros((len(x), n_components))\n",
    "    alpha[0, :] = start_probs[:] * observation_probs[:, x[0]]\n",
    "\n",
    "    for t in range(1, len(x), 1):\n",
    "        token = x[t]\n",
    "        for i in range(n_components):\n",
    "            alpha[t, i] = (\n",
    "                alpha[t - 1, :] @ transition_probs[:, i]\n",
    "            ) * observation_probs[i, token]\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def _beta(x, start_probs, transition_probs, observation_probs):\n",
    "    n_components = start_probs.shape[0]\n",
    "    beta = np.zeros((len(x), n_components))\n",
    "    beta[-1, :] = np.ones((n_components))\n",
    "\n",
    "    for t in range(len(x) - 2, -1, -1):\n",
    "        next_token = x[t + 1]\n",
    "        for i in range(n_components):\n",
    "            beta[t, i] = (\n",
    "                beta[t + 1] * observation_probs[:, next_token]\n",
    "            ) @ transition_probs[i, :]\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def _xi(x, alpha, beta, start_probs, transition_probs, observation_probs):\n",
    "    n_components = start_probs.shape[0]\n",
    "    xi = np.zeros((len(x) - 1, n_components, n_components))\n",
    "\n",
    "    for t in range(0, len(x) - 1, 1):\n",
    "        next_token = x[t + 1]\n",
    "        denominator = (\n",
    "            (alpha[t, :].T @ transition_probs) *\n",
    "            observation_probs[:, next_token].T\n",
    "        ) @ beta[t + 1, :]\n",
    "        for i in range(n_components):\n",
    "            numerator = alpha[t, i] * transition_probs[i, :] * (\n",
    "                observation_probs[:, next_token].T * beta[t + 1, :].T\n",
    "            )\n",
    "            xi[t, i, :] = numerator / denominator\n",
    "\n",
    "    return xi\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def _gamma(x, xi):\n",
    "    gamma = np.sum(xi, axis=2)\n",
    "    gamma = np.vstack(\n",
    "        (gamma, np.sum(xi[len(x) - 2, :, :], axis=0).reshape((1, -1)))\n",
    "    )\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, parallel=True)\n",
    "def _score(X, start_probs, transition_probs, observation_probs):\n",
    "    result = np.zeros((len(X)))\n",
    "\n",
    "    for i in nb.prange(len(X)):\n",
    "        alpha = _alpha(X[i], start_probs, transition_probs, observation_probs)\n",
    "        result[i] = np.sum(alpha[-1, :])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, parallel=True)\n",
    "def _fit(X, n_iter, n_components, start_probs, transition_probs, observation_probs):\n",
    "    for iii in range(n_iter):\n",
    "        print(f\"Iter: {iii}\")\n",
    "        R = len(X)\n",
    "\n",
    "        xis = np.zeros((R, len(X[0]) - 1, n_components, n_components))\n",
    "        gammas = np.zeros((R, len(X[0]), n_components))\n",
    "\n",
    "        for r in nb.prange(R):\n",
    "            x = X[r]\n",
    "\n",
    "            alpha = _alpha(x, start_probs,\n",
    "                           transition_probs, observation_probs)\n",
    "            beta = _beta(x, start_probs,\n",
    "                         transition_probs, observation_probs)\n",
    "            xis[r, :, :, :] = _xi(x, alpha, beta, start_probs,\n",
    "                                  transition_probs, observation_probs)\n",
    "            gammas[r, :, :] = _gamma(x, xis[r, :, :, :])\n",
    "\n",
    "        # start_probs = np.sum(gammas[:, 0, :], axis=0) / R\n",
    "\n",
    "        transition_probs = xis.sum(0).sum(0) / (\n",
    "            gammas[:, 0:-1, :].sum(0).sum(0).reshape(-1, 1)\n",
    "        )\n",
    "\n",
    "        denominator = gammas.sum(0).sum(0).reshape(-1, 1)\n",
    "        for k in range(observation_probs.shape[1]):\n",
    "            sum_probs = np.zeros((len(X), n_components))\n",
    "            for r in nb.prange(R):\n",
    "                sum_probs[r] = gammas[r][X[r] == k, :].sum(0)\n",
    "            observation_probs[:, k] = sum_probs.sum(0)\n",
    "        observation_probs = observation_probs / denominator\n",
    "\n",
    "    return (start_probs, transition_probs, observation_probs)\n",
    "\n",
    "\n",
    "class HMMEstimator(skbase.BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        end_prob=1.0,\n",
    "        start_probs=None,\n",
    "        transition_probs=None,\n",
    "        observation_probs=None,\n",
    "        n_components=1,\n",
    "        n_iter=10,\n",
    "    ):\n",
    "        self.end_prob = end_prob\n",
    "        self.start_probs = start_probs\n",
    "        self.transition_probs = transition_probs\n",
    "        self.observation_probs = observation_probs\n",
    "        self.n_components = n_components\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        result = []\n",
    "        for x in X:\n",
    "            alpha = _alpha(x, self.start_probs,\n",
    "                           self.transition_probs, self.observation_probs)\n",
    "            result.append(sum(alpha[-1, :]))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        (self.start_probs, self.transition_probs, self.observation_probs) = _fit(\n",
    "            X,\n",
    "            self.n_iter,\n",
    "            self.n_components,\n",
    "            self.start_probs,\n",
    "            self.transition_probs,\n",
    "            self.observation_probs\n",
    "        )\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    sections = open(path).read().split(\"\\n\\n\")\n",
    "\n",
    "    start_probs = np.array(re.sub(r\"^\\w+: \\d+\\n\", \"\", sections[0]).split(\"\\t\")).astype(\n",
    "        float\n",
    "    )\n",
    "    transition_probs = np.array(\n",
    "        [row.split(\"\\t\") for row in re.sub(\n",
    "            r\"^\\w+: \\d+\\n\", \"\", sections[1]).split(\"\\n\")]\n",
    "    ).astype(float)\n",
    "    observation_probs = np.array(\n",
    "        [\n",
    "            row.split(\"\\t\")\n",
    "            for row in re.sub(r\"^\\w+: \\d+\\n\", \"\", sections[2]).split(\"\\n\")[:-1]\n",
    "        ]\n",
    "    ).astype(float)\n",
    "\n",
    "    return HMMEstimator(\n",
    "        start_probs=start_probs,\n",
    "        transition_probs=transition_probs,\n",
    "        observation_probs=observation_probs.T,\n",
    "        n_components=start_probs.size,\n",
    "        n_iter=5,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_model(path, model):\n",
    "    text = \"\"\n",
    "    text += f\"initial: {model.start_probs.shape[0]}\\n\"\n",
    "    text += (\n",
    "        np.array2string(model.start_probs, separator=\"\\t\", max_line_width=200)\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "    )\n",
    "    text += \"\\n\\n\"\n",
    "    text += f\"transition: {model.transition_probs.shape[0]}\\n\"\n",
    "    text += (\n",
    "        np.array2string(model.transition_probs,\n",
    "                        separator=\"\\t\", max_line_width=200)\n",
    "        .replace(\" [\", \"\")\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "    )\n",
    "    text += \"\\n\\n\"\n",
    "    text += f\"observation: {model.observation_probs.T.shape[1]}\\n\"\n",
    "    text += (\n",
    "        np.array2string(model.observation_probs.T,\n",
    "                        separator=\"\\t\", max_line_width=200)\n",
    "        .replace(\" [\", \"\")\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "    )\n",
    "    text += \"\\n\"\n",
    "\n",
    "    open(path, \"w+\").write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32c3cd",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Now we will load `hmm_data` corpus and split it into `TestSet` and `TrainSet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Iter: 1\n",
      "Iter: 2\n",
      "Iter: 3\n",
      "Iter: 4\n",
      "Iter: 5\n",
      "Iter: 6\n",
      "Iter: 7\n",
      "Iter: 8\n",
      "Iter: 9\n",
      "Iter: 10\n",
      "Iter: 11\n",
      "Iter: 12\n",
      "Iter: 13\n",
      "Iter: 14\n",
      "Iter: 15\n",
      "Iter: 16\n",
      "Iter: 17\n",
      "Iter: 18\n",
      "Iter: 19\n",
      "Iter: 20\n",
      "Iter: 21\n",
      "Iter: 22\n",
      "Iter: 23\n",
      "Iter: 24\n",
      "Iter: 25\n",
      "Iter: 26\n",
      "Iter: 27\n",
      "Iter: 28\n",
      "Iter: 29\n",
      "Iter: 30\n",
      "Iter: 31\n",
      "Iter: 32\n",
      "Iter: 33\n",
      "Iter: 34\n",
      "Iter: 35\n",
      "Iter: 36\n",
      "Iter: 37\n",
      "Iter: 38\n",
      "Iter: 39\n",
      "Iter: 40\n",
      "Iter: 41\n",
      "Iter: 42\n",
      "Iter: 43\n",
      "Iter: 44\n",
      "Iter: 45\n",
      "Iter: 46\n",
      "Iter: 47\n",
      "Iter: 48\n",
      "Iter: 49\n",
      "Iter: 50\n",
      "Iter: 51\n",
      "Iter: 52\n",
      "Iter: 53\n",
      "Iter: 54\n",
      "Iter: 55\n",
      "Iter: 56\n",
      "Iter: 57\n",
      "Iter: 58\n",
      "Iter: 59\n",
      "Iter: 60\n",
      "Iter: 61\n",
      "Iter: 62\n",
      "Iter: 63\n",
      "Iter: 64\n",
      "Iter: 65\n",
      "Iter: 66\n",
      "Iter: 67\n",
      "Iter: 68\n",
      "Iter: 69\n",
      "Iter: 70\n",
      "Iter: 71\n",
      "Iter: 72\n",
      "Iter: 73\n",
      "Iter: 74\n",
      "Iter: 75\n",
      "Iter: 76\n",
      "Iter: 77\n",
      "Iter: 78\n",
      "Iter: 79\n",
      "Iter: 80\n",
      "Iter: 81\n",
      "Iter: 82\n",
      "Iter: 83\n",
      "Iter: 84\n",
      "Iter: 85\n",
      "Iter: 86\n",
      "Iter: 87\n",
      "Iter: 88\n",
      "Iter: 89\n",
      "Iter: 90\n",
      "Iter: 91\n",
      "Iter: 92\n",
      "Iter: 93\n",
      "Iter: 94\n",
      "Iter: 95\n",
      "Iter: 96\n",
      "Iter: 97\n",
      "Iter: 98\n",
      "Iter: 99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.5, 0.5]),\n",
       " array([[0.53816345, 0.46183655],\n",
       "        [0.48664443, 0.51335557]]),\n",
       " array([[0.16277513, 0.26258073, 0.57464414],\n",
       "        [0.2514996 , 0.27780971, 0.47069069]]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./exercise_2/data.txt\")\n",
    "V = data[\"Visible\"].values\n",
    "\n",
    "# Transition Probabilities\n",
    "A = np.ones((2, 2))\n",
    "A = A / np.sum(A, axis=1)\n",
    "\n",
    "# Emission Probabilities\n",
    "B = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "B = B / np.sum(B, axis=1).reshape((-1, 1))\n",
    "\n",
    "# Equal Probabilities for the initial distribution\n",
    "Pi = np.array((0.5, 0.5))\n",
    "\n",
    "_fit(np.array([V]), 100, 2, Pi, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9278c29f1c5526d5663cab0214876a9a1ad235f0a8fdeebad627cd7666833d94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
