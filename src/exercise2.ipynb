{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Answers\n",
    "\n",
    "- **Answer Set**: No. 02\n",
    "- **Full Name**: Mohammad Hosein Nemati\n",
    "- **Student Code**: `610300185`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595aa20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed694d",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "In this section we will done some basic steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cf505",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "Before begin, we must import these required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import re as re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.base as skbase\n",
    "import sklearn.utils as skutils\n",
    "import sklearn.pipeline as skpipeline\n",
    "import sklearn.preprocessing as skprocessing\n",
    "import sklearn.model_selection as skselection\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "\n",
    "# import exercise_2.hmm as hmm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "sk.set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as re\n",
    "\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.base as skbase\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, fastmath=True)\n",
    "def _alpha(x, n_components, start_probs, transition_probs, observation_probs):\n",
    "    alpha = np.zeros((len(x), n_components))\n",
    "    alpha[0, :] = start_probs[:] * observation_probs[:, x[0]]\n",
    "\n",
    "    for t in range(1, len(x), 1):\n",
    "        token = x[t]\n",
    "        for i in range(n_components):\n",
    "            alpha[t, i] = observation_probs[i, token] * sum([\n",
    "                alpha[t - 1, j] * transition_probs[j, i]\n",
    "                for j in range(n_components)\n",
    "            ])\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, fastmath=True)\n",
    "def _beta(x, n_components, start_probs, transition_probs, observation_probs):\n",
    "    beta = np.zeros((len(x), n_components))\n",
    "    beta[-1, :] = np.ones((1, n_components))\n",
    "\n",
    "    for t in range(len(x) - 2, -1, -1):\n",
    "        next_token = x[t + 1]\n",
    "        for i in range(n_components):\n",
    "            beta[t, i] = sum([\n",
    "                beta[t + 1, j]\n",
    "                * transition_probs[i, j]\n",
    "                * observation_probs[j, next_token]\n",
    "                for j in range(n_components)\n",
    "            ])\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, fastmath=True)\n",
    "def _xi(x, alpha, beta, n_components, start_probs, transition_probs, observation_probs):\n",
    "    xi = np.zeros((len(x) - 1, n_components, n_components))\n",
    "\n",
    "    for t in range(0, len(x) - 1, 1):\n",
    "        next_token = x[t + 1]\n",
    "        for i in range(n_components):\n",
    "            for j in range(n_components):\n",
    "                xi[t, i, j] = (\n",
    "                    alpha[t, i]\n",
    "                    * transition_probs[i, j]\n",
    "                    * beta[t + 1, j]\n",
    "                    * observation_probs[j, next_token]\n",
    "                ) / sum([\n",
    "                    alpha[t, k]\n",
    "                    * transition_probs[k, w]\n",
    "                    * beta[t + 1, w]\n",
    "                    * observation_probs[w, next_token]\n",
    "                    for w in range(n_components)\n",
    "                    for k in range(n_components)\n",
    "                ])\n",
    "\n",
    "    return xi\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, fastmath=True)\n",
    "def _gamma(x, alpha, beta, n_components, start_probs, transition_probs, observation_probs):\n",
    "    gamma = np.zeros((len(x), n_components))\n",
    "\n",
    "    for t in range(0, len(x), 1):\n",
    "        for i in range(n_components):\n",
    "            gamma[t, i] = alpha[t, i] * beta[t, i] / sum([\n",
    "                (alpha[t, j] * beta[t, j])\n",
    "                for j in range(n_components)\n",
    "            ])\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True, parallel=True, fastmath=True)\n",
    "def _fit(X, n_iter, n_components, start_probs, transition_probs, observation_probs):\n",
    "    for _ in range(n_iter):\n",
    "        R = len(X)\n",
    "\n",
    "        xis = np.zeros((R, len(X[0]) - 1, n_components, n_components))\n",
    "        gammas = np.zeros((R, len(X[0]), n_components))\n",
    "\n",
    "        for r in nb.prange(R):\n",
    "            x = X[r]\n",
    "\n",
    "            alpha = _alpha(x, n_components, start_probs,\n",
    "                           transition_probs, observation_probs)\n",
    "            beta = _beta(x, n_components, start_probs,\n",
    "                         transition_probs, observation_probs)\n",
    "            xis[r, :, :, :] = _xi(x, alpha, beta, n_components, start_probs,\n",
    "                                  transition_probs, observation_probs)\n",
    "            gammas[r, :, :] = _gamma(x, alpha, beta, n_components, start_probs,\n",
    "                                     transition_probs, observation_probs)\n",
    "\n",
    "            print(alpha)\n",
    "            print(beta)\n",
    "\n",
    "        for i in range(n_components):\n",
    "            start_probs[i] = sum([\n",
    "                gammas[r, 0, i]\n",
    "                for r in range(R)\n",
    "            ]) / R\n",
    "\n",
    "        for i in range(n_components):\n",
    "            for j in range(n_components):\n",
    "                transition_probs[i, j] = sum([\n",
    "                    xis[r, t, i, j]\n",
    "                    for r in range(R)\n",
    "                    for t in range(len(X[r]) - 1)\n",
    "                ]) / sum([\n",
    "                    gammas[r, t, i]\n",
    "                    for r in range(R)\n",
    "                    for t in range(len(X[r]) - 1)\n",
    "                ])\n",
    "\n",
    "        for i in range(n_components):\n",
    "            for k in range(n_components):\n",
    "                observation_probs[i, k] = sum([\n",
    "                    gammas[r, t, i]\n",
    "                    for r in range(R)\n",
    "                    for t in range(len(X[r]))\n",
    "                    if X[r][t] == k\n",
    "                ]) / sum([\n",
    "                    gammas[r, t, i]\n",
    "                    for r in range(R)\n",
    "                    for t in range(len(X[r]))\n",
    "                ])\n",
    "\n",
    "    return (start_probs, transition_probs, observation_probs)\n",
    "\n",
    "\n",
    "class HMMEstimator(skbase.BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        end_prob=1.0,\n",
    "        start_probs=None,\n",
    "        transition_probs=None,\n",
    "        observation_probs=None,\n",
    "        n_components=1,\n",
    "        n_iter=10,\n",
    "    ):\n",
    "        self.end_prob = end_prob\n",
    "        self.start_probs = start_probs\n",
    "        self.transition_probs = transition_probs\n",
    "        self.observation_probs = observation_probs\n",
    "        self.n_components = n_components\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        result = []\n",
    "        for x in X:\n",
    "            alpha = _alpha(x, self.n_components, self.start_probs,\n",
    "                           self.transition_probs, self.observation_probs)\n",
    "            result.append(sum(alpha[-1, :]))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        (self.start_probs, self.transition_probs, self.observation_probs) = _fit(\n",
    "            X,\n",
    "            self.n_iter,\n",
    "            self.n_components,\n",
    "            self.start_probs,\n",
    "            self.transition_probs,\n",
    "            self.observation_probs\n",
    "        )\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    sections = open(path).read().split(\"\\n\\n\")\n",
    "\n",
    "    start_probs = np.array(re.sub(r\"^\\w+: \\d+\\n\", \"\", sections[0]).split(\"\\t\")).astype(\n",
    "        float\n",
    "    )\n",
    "    transition_probs = np.array(\n",
    "        [row.split(\"\\t\") for row in re.sub(\n",
    "            r\"^\\w+: \\d+\\n\", \"\", sections[1]).split(\"\\n\")]\n",
    "    ).astype(float)\n",
    "    observation_probs = np.array(\n",
    "        [\n",
    "            row.split(\"\\t\")\n",
    "            for row in re.sub(r\"^\\w+: \\d+\\n\", \"\", sections[2]).split(\"\\n\")[:-1]\n",
    "        ]\n",
    "    ).astype(float)\n",
    "\n",
    "    return HMMEstimator(\n",
    "        start_probs=start_probs,\n",
    "        transition_probs=transition_probs,\n",
    "        observation_probs=observation_probs.T,\n",
    "        n_components=start_probs.size,\n",
    "        n_iter=5,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_model(path, model):\n",
    "    text = \"\"\n",
    "    text += f\"initial: {model.start_probs.shape[0]}\\n\"\n",
    "    text += (\n",
    "        np.array2string(model.start_probs, separator=\"\\t\", max_line_width=200)\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "    )\n",
    "    text += \"\\n\\n\"\n",
    "    text += f\"transition: {model.transition_probs.shape[0]}\\n\"\n",
    "    text += (\n",
    "        np.array2string(model.transition_probs,\n",
    "                        separator=\"\\t\", max_line_width=200)\n",
    "        .replace(\" [\", \"\")\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "    )\n",
    "    text += \"\\n\\n\"\n",
    "    text += f\"observation: {model.observation_probs.T.shape[1]}\\n\"\n",
    "    text += (\n",
    "        np.array2string(model.observation_probs.T,\n",
    "                        separator=\"\\t\", max_line_width=200)\n",
    "        .replace(\" [\", \"\")\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "    )\n",
    "    text += \"\\n\"\n",
    "\n",
    "    open(path, \"w+\").write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32c3cd",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Now we will load `hmm_data` corpus and split it into `TestSet` and `TrainSet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HMMEstimator(n_components=6, n_iter=100,\n",
       "             observation_probs=array([[4.91535393e-001, 3.18118444e-001, 1.90346163e-001,\n",
       "        4.46577846e-105, 0.00000000e+000, 2.24006032e-067],\n",
       "       [7.33279790e-002, 1.13506493e-001, 8.13165528e-001,\n",
       "        1.75899143e-022, 2.95684185e-042, 2.00696797e-024],\n",
       "       [4.76761198e-007, 6.85647232e-003, 5.82600830e-001,\n",
       "        3.65253459e-001, 4.52887619e-002, 1.3389342...\n",
       "       [2.43213316e-19, 3.09482161e-02, 4.91902423e-01, 2.96137023e-01,\n",
       "        1.80458523e-01, 5.53814769e-04],\n",
       "       [1.12997474e-23, 4.99350547e-03, 2.48170039e-01, 2.80162905e-01,\n",
       "        4.40493273e-01, 2.61802770e-02],\n",
       "       [2.01506719e-26, 3.29565814e-04, 5.92548180e-06, 9.68929430e-17,\n",
       "        1.34754581e-14, 9.99664509e-01],\n",
       "       [3.04605706e-22, 5.97574771e-01, 5.43931519e-20, 8.62756321e-37,\n",
       "        5.74974194e-22, 4.02425229e-01]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv(\"../lib/hmm_data/seq_model_01.txt\", header=None, names=[\"Text\"]).head(10).to_numpy().flatten()\n",
    "train_features = list(map(lambda x: np.array(list(map(lambda t: ord(t) - ord('A'), x))), train_features))\n",
    "\n",
    "model = load_model(\"../lib/hmm_data/model_init.txt\")\n",
    "model.n_iter = 100\n",
    "\n",
    "model.fit(train_features)\n",
    "# hmm.save_model(output_path, model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9278c29f1c5526d5663cab0214876a9a1ad235f0a8fdeebad627cd7666833d94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
